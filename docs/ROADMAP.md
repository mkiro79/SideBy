# ROADMAP - SideBy

Este documento describe las mejoras futuras y caracter√≠sticas planificadas para el proyecto SideBy, organizadas por RFC (Request for Comments).

## Prop√≥sito

El ROADMAP sirve para:
- **Documentar mejoras identificadas** durante el desarrollo que no son cr√≠ticas para el MVP
- **Priorizar features** para futuras iteraciones
- **Mantener contexto t√©cnico** de decisiones arquitect√≥nicas
- **Facilitar la planificaci√≥n** de sprints futuros

---

## RFC-001: AUTH & IDENTITY

### Mejoras Planificadas

_Pendiente: Agregar mejoras identificadas para autenticaci√≥n e identidad_

---

## RFC-002: DATA INGESTION

### Mejoras Planificadas

### üßπ Dataset Cleanup Job (Limpieza Autom√°tica de Datasets Abandonados)

**Estado:** Propuesta  
**Prioridad:** Baja  
**Esfuerzo Estimado:** 1-2 d√≠as  
**Versi√≥n Target:** v0.4.0

#### Contexto

Durante la implementaci√≥n del m√≥dulo de Datasets (RFC-003), se identific√≥ la necesidad de un mecanismo de limpieza autom√°tica para datasets que quedan en estado `processing` indefinidamente. Estos datasets "abandonados" ocupan espacio en la base de datos sin aportar valor.

**Escenario problem√°tico:**
1. Usuario sube dos archivos CSV (Paso 1)
2. Los archivos se procesan correctamente y el dataset queda en `status: processing`
3. Usuario abandona el flujo sin completar el Paso 3 (configuraci√≥n de mapping)
4. El dataset queda hu√©rfano, ocupando espacio innecesariamente

#### Soluci√≥n Propuesta

Implementar un **Cron Job** que ejecute peri√≥dicamente una tarea de limpieza:

1. **Buscar datasets abandonados:**
   ```typescript
   const cutoffDate = new Date();
   cutoffDate.setHours(cutoffDate.getHours() - 24); // 24 horas
   
   const abandoned = await repository.findAbandoned(cutoffDate);
   // Retorna datasets con status="processing" y createdAt < cutoffDate
   ```

2. **Eliminar datasets autom√°ticamente:**
   ```typescript
   for (const dataset of abandoned) {
     await repository.delete(dataset.id);
     logger.info(`Deleted abandoned dataset: ${dataset.id}`);
   }
   ```

3. **Configuraci√≥n v√≠a variables de entorno:**
   ```env
   CLEANUP_JOB_ENABLED=true
   CLEANUP_JOB_SCHEDULE="0 2 * * *"  # Diario a las 2 AM
   ABANDONED_DATASET_HOURS=24        # Considerar abandonado despu√©s de 24h
   ```

#### Implementaci√≥n

**Archivo:** `src/modules/datasets/jobs/cleanup-abandoned.job.ts`

```typescript
import { MongoDatasetRepository } from '../infrastructure/mongoose/MongoDatasetRepository.js';
import { DatasetRules } from '../domain/validation.rules.js';
import logger from '@/utils/logger.js';

export async function cleanupAbandonedDatasets(): Promise<void> {
  try {
    const repository = new MongoDatasetRepository();
    const cutoffDate = new Date();
    cutoffDate.setHours(cutoffDate.getHours() - DatasetRules.ABANDONED_DATASET_HOURS);

    const abandoned = await repository.findAbandoned(cutoffDate);
    logger.info(`Found ${abandoned.length} abandoned datasets`);

    for (const dataset of abandoned) {
      await repository.delete(dataset.id);
      logger.info(`Deleted abandoned dataset: ${dataset.id}`);
    }

    logger.info('Cleanup job completed successfully');
  } catch (error) {
    logger.error({ err: error }, 'Cleanup job failed');
  }
}
```

**Integraci√≥n con node-cron:**

```typescript
// En src/index.ts o src/jobs/scheduler.ts
import cron from 'node-cron';
import { cleanupAbandonedDatasets } from '@/modules/datasets/jobs/cleanup-abandoned.job.js';

// Ejecutar diariamente a las 2 AM
if (process.env.CLEANUP_JOB_ENABLED === 'true') {
  cron.schedule('0 2 * * *', async () => {
    logger.info('Starting dataset cleanup job');
    await cleanupAbandonedDatasets();
  });
}
```

#### Tareas de Implementaci√≥n

- [ ] Crear archivo `cleanup-abandoned.job.ts`
- [ ] Instalar dependencia `node-cron`
- [ ] A√±adir configuraci√≥n en `.env` y `.env.example`
- [ ] Integrar scheduler en `index.ts`
- [ ] Crear tests unitarios del job
- [ ] Documentar en README de operaciones
- [ ] Configurar monitoreo/alertas (opcional)

#### Consideraciones

- **Notificaci√≥n al usuario:** En v0.5.0, considerar enviar email de aviso antes de eliminar
- **Soft delete:** Implementar eliminaci√≥n l√≥gica en lugar de f√≠sica (preservar para auditor√≠a)
- **M√©tricas:** Trackear n√∫mero de datasets eliminados para an√°lisis de abandono

---

## RFC-003: SCHEMA MAPPING

### üîÑ Toggle de Tipo de Columna (Column Type Override)

**Estado:** Propuesta  
**Prioridad:** Media  
**Esfuerzo Estimado:** 3-5 d√≠as  
**Versi√≥n Target:** v0.3.0

#### Contexto

Durante la implementaci√≥n del **RFC-003-A (Simplified Auto-Mapping UI)**, se identific√≥ una limitaci√≥n del sistema de auto-clasificaci√≥n:

- **Problema:** El campo "Year" (A√±o) es detectado autom√°ticamente como **m√©trica num√©rica** (ej: 2023, 2024)
- **Realidad:** En la mayor√≠a de casos, "Year" es conceptualmente una **dimensi√≥n categ√≥rica** para segmentar datos
- **Impacto:** El usuario no puede usar "Year" para agrupar/filtrar datos, solo como valor num√©rico

#### Soluci√≥n Propuesta

Implementar un **sistema de toggle de tipo de columna** que permita al usuario:

1. **Override manual del tipo auto-detectado:**
   - Cambiar una columna de "M√©trica" ‚Üí "Dimensi√≥n"
   - Cambiar una columna de "Dimensi√≥n" ‚Üí "M√©trica"
   - Cambiar "Fecha" ‚Üí "Dimensi√≥n" (caso de Year/Month strings)

2. **Transformaci√≥n de datos:**
   ```typescript
   // Ejemplo: Year 2023 (number) ‚Üí "2023" (string)
   if (typeOverride === 'dimension' && originalType === 'numeric') {
     transformedValue = String(originalValue);
   }
   ```

3. **Persistencia del override:**
   ```typescript
   interface ColumnMapping {
     [columnName: string]: {
       sourceColumn: string;
       targetColumn: string;
       format: KPIFormat; // 'number' | 'currency' | 'string' | 'date'
       originalType?: 'numeric' | 'string' | 'date';  // Nuevo
       typeOverride?: 'metric' | 'dimension' | 'date'; // Nuevo
     };
   }
   ```

#### Dise√±o de UI

**Opci√≥n A - Bot√≥n Toggle Inline:**
```
‚úì [Year]          [M√©trica ‚áÑ Dimensi√≥n]
‚úì [Revenue]       [M√©trica]
‚úì [Product Name]  [Dimensi√≥n]
```

**Opci√≥n B - Dropdown de Tipo:**
```
‚úì [Year]          [‚ñº Dimensi√≥n]  (Detectado: M√©trica)
                      ‚îú‚îÄ M√©trica
                      ‚îú‚îÄ Dimensi√≥n
                      ‚îî‚îÄ Fecha
```

**Recomendaci√≥n:** Opci√≥n B es m√°s flexible y permite todos los cambios de tipo.

#### Casos de Uso

1. **Year como Dimensi√≥n:**
   ```
   Detectado: M√©trica (2023, 2024)
   Override:  Dimensi√≥n ‚Üí "2023", "2024"
   Uso:       Filtrar/agrupar por a√±o
   ```

2. **ID num√©rico como Dimensi√≥n:**
   ```
   Detectado: M√©trica (10001, 10002)
   Override:  Dimensi√≥n ‚Üí "10001", "10002"
   Uso:       Identificador √∫nico, no agregable
   ```

3. **Month string como Fecha:**
   ```
   Detectado: Dimensi√≥n ("2024-01", "2024-02")
   Override:  Fecha ‚Üí Parse como Date
   Uso:       Gr√°fico de evoluci√≥n temporal
   ```

#### Tareas de Implementaci√≥n

- [ ] **Backend (API):**
  - [ ] Extender `ColumnMapping` type con `originalType` y `typeOverride`
  - [ ] Agregar l√≥gica de transformaci√≥n en data processing pipeline
  - [ ] Tests unitarios para transformaciones de tipo

- [ ] **Frontend (Client):**
  - [ ] UI: Agregar dropdown/toggle de tipo en `ColumnMappingStep`
  - [ ] State: Actualizar `useWizardState` para manejar overrides
  - [ ] Validation: Prevenir overrides inv√°lidos (ej: text ‚Üí numeric)
  - [ ] Tests: Vitest + RTL para interacciones de toggle

- [ ] **Integration:**
  - [ ] End-to-end test para flujo completo con override
  - [ ] Documentaci√≥n de usuario (capturas UI)

#### Referencias

- **Archivo:** `solution-sideby/apps/client/src/features/dataset/components/wizard/ColumnMappingStep.simplified.tsx`
- **Funci√≥n Auto-Clasificaci√≥n:** `solution-sideby/apps/client/src/features/dataset/utils/autoClassify.ts`
- **Types:** `solution-sideby/apps/client/src/features/dataset/types/wizard.types.ts`

#### Notas T√©cnicas

- **Backward Compatibility:** Los mappings sin `typeOverride` usar√°n el tipo auto-detectado (no breaking change)
- **Validaci√≥n:** No permitir override de `date` ‚Üí `numeric` (p√©rdida de informaci√≥n)
- **Performance:** Transformaciones de tipo se ejecutan una sola vez durante import, no en runtime

---

### ‚ö° Migraci√≥n a React Query (TanStack Query) para Server State

**Estado:** ‚úÖ Dise√±o Completado (ver RFC-React-Query-Migration)  
**Prioridad:** Alta - Requerido para RFC-004  
**Esfuerzo Estimado:** 2 d√≠as  
**Versi√≥n Target:** v0.3.1  
**RFC:** `docs/design/RFC-React-Query-Migration.md`

#### Contexto

Actualmente, el frontend maneja el **server state** (datos del backend) con hooks manuales basados en `useState` + `useEffect`. Esta implementaci√≥n funciona pero tiene limitaciones:

**Problemas Actuales:**
1. **Sin cache:** Cada vez que se monta un componente, se hace fetch de nuevo
2. **Sin sincronizaci√≥n:** Si actualizas un dataset en una p√°gina, otras p√°ginas no se refrescan
3. **C√≥digo boilerplate:** Cada hook repite la misma l√≥gica de loading/error/data
4. **Sin optimistic updates:** La UI se actualiza solo despu√©s de la respuesta del servidor
5. **Sin deduplicaci√≥n:** Si 2 componentes piden el mismo dato, hace 2 requests
6. **Sin revalidaci√≥n:** No hay estrategia de stale-while-revalidate

**Ejemplo de c√≥digo actual (manual):**
```typescript
// features/dataset/hooks/useDataset.ts (ACTUAL)
export function useDataset(datasetId: string | null) {
  const [dataset, setDataset] = useState<Dataset | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    if (datasetId) {
      setIsLoading(true);
      getDataset(datasetId)
        .then(setDataset)
        .catch(setError)
        .finally(() => setIsLoading(false));
    }
  }, [datasetId]);

  return { dataset, isLoading, error };
}
```

#### Soluci√≥n Propuesta

Migrar a **React Query (TanStack Query v5)** para aprovechar:

1. **Cache inteligente:** Los datasets se cachean autom√°ticamente por `queryKey`
2. **Invalidaci√≥n autom√°tica:** Despu√©s de un `PATCH`, invalidar el cache del `GET`
3. **Estados simplificados:** No m√°s boilerplate de `useState` para loading/error/data
4. **Optimistic updates:** Actualizar UI antes de que responda el servidor
5. **Deduplicaci√≥n:** M√∫ltiples componentes pueden usar la misma query sin duplicar requests
6. **Revalidaci√≥n autom√°tica:** Datos frescos al volver a la pesta√±a (stale-while-revalidate)
7. **DevTools:** Panel de debugging para ver queries y cache en tiempo real

**Ejemplo con React Query (PROPUESTO):**
```typescript
// features/dataset/hooks/useDataset.ts (CON REACT QUERY)
import { useQuery } from '@tanstack/react-query';

export function useDataset(datasetId: string | null) {
  return useQuery({
    queryKey: ['dataset', datasetId],
    queryFn: () => getDataset(datasetId!),
    enabled: !!datasetId,
    staleTime: 5 * 60 * 1000, // 5 minutos
  });
}
```

**Beneficio de invalidaci√≥n autom√°tica:**
```typescript
// features/dataset/hooks/useDatasetMapping.ts
import { useMutation, useQueryClient } from '@tanstack/react-query';

export function useDatasetMapping() {
  const queryClient = useQueryClient();

  return useMutation({
    mutationFn: ({ id, payload }) => updateMapping(id, payload),
    onSuccess: (_, { id }) => {
      // ‚úÖ Invalida autom√°ticamente el GET del dataset
      queryClient.invalidateQueries({ queryKey: ['dataset', id] });
      // ‚úÖ Tambi√©n invalida la lista de datasets
      queryClient.invalidateQueries({ queryKey: ['datasets'] });
    },
  });
}
```

#### Alcance de Migraci√≥n

**M√≥dulos a migrar:**

1. **Datasets Module:**
   - `useDataset` ‚Üí `useQuery`
   - `useDatasetsList` ‚Üí `useQuery`
   - `useDatasetUpload` ‚Üí `useMutation`
   - `useDatasetMapping` ‚Üí `useMutation`
   - `useDeleteDataset` ‚Üí `useMutation` (si existe)

2. **Auth Module (opcional):**
   - `useUser` ‚Üí `useQuery` (perfil de usuario)
   - `useLogin` / `useRegister` ‚Üí `useMutation`

3. **Future Modules:**
   - Cualquier nuevo m√≥dulo que haga fetching de datos del backend

#### Implementaci√≥n

**Paso 1: Instalaci√≥n**
```bash
npm install @tanstack/react-query @tanstack/react-query-devtools
```

**Paso 2: Setup del QueryClient**
```typescript
// src/infrastructure/api/queryClient.ts
import { QueryClient } from '@tanstack/react-query';

export const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      staleTime: 5 * 60 * 1000, // 5 minutos
      retry: 1,
      refetchOnWindowFocus: true,
    },
    mutations: {
      retry: 0,
    },
  },
});
```

**Paso 3: Wrapping en App.tsx**
```typescript
// src/App.tsx
import { QueryClientProvider } from '@tanstack/react-query';
import { ReactQueryDevtools } from '@tanstack/react-query-devtools';
import { queryClient } from '@/infrastructure/api/queryClient';

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      {/* App content */}
      <ReactQueryDevtools initialIsOpen={false} />
    </QueryClientProvider>
  );
}
```

**Paso 4: Migrar hooks uno por uno**

Ejemplo de migraci√≥n completa:

```typescript
// ANTES (manual)
export function useDatasetsList() {
  const [datasets, setDatasets] = useState<Dataset[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    setIsLoading(true);
    listDatasets()
      .then(setDatasets)
      .catch((err) => setError(err.message))
      .finally(() => setIsLoading(false));
  }, []);

  return { datasets, isLoading, error };
}

// DESPU√âS (React Query)
export function useDatasetsList() {
  return useQuery({
    queryKey: ['datasets'],
    queryFn: listDatasets,
  });
}
```

#### Tareas de Implementaci√≥n

- [ ] **Setup:**
  - [ ] Instalar `@tanstack/react-query` y `@tanstack/react-query-devtools`
  - [ ] Crear `queryClient.ts` con configuraci√≥n por defecto
  - [ ] Wrappear App con `QueryClientProvider`
  - [ ] Habilitar DevTools en modo desarrollo

- [ ] **Migraci√≥n de Hooks (Datasets):**
  - [ ] `useDataset` ‚Üí `useQuery`
  - [ ] `useDatasetsList` ‚Üí `useQuery`
  - [ ] `useDatasetUpload` ‚Üí `useMutation` con invalidaci√≥n
  - [ ] `useDatasetMapping` ‚Üí `useMutation` con invalidaci√≥n
  - [ ] `useDeleteDataset` ‚Üí `useMutation` con invalidaci√≥n

- [ ] **Tests:**
  - [ ] Actualizar tests de hooks para usar `QueryClientProvider` wrapper
  - [ ] Crear utils para testing con React Query (`createTestQueryClient`)
  - [ ] Tests de invalidaci√≥n de cache

- [ ] **Optimizaciones:**
  - [ ] Implementar optimistic updates para mutations
  - [ ] Configurar `staleTime` y `cacheTime` por query seg√∫n necesidades
  - [ ] Prefetching de datasets en lista (hover)

- [ ] **Documentaci√≥n:**
  - [ ] Actualizar README del m√≥dulo frontend
  - [ ] Documentar convenciones de queryKeys (`['entity', id]`)
  - [ ] Gu√≠a de uso de DevTools

#### Beneficios Esperados

**UX:**
- ‚ö° Respuesta instant√°nea al volver a p√°ginas visitadas (cache)
- ‚úÖ Sincronizaci√≥n autom√°tica entre p√°ginas (invalidaci√≥n)
- üéØ Feedback inmediato en acciones del usuario (optimistic updates)

**DX (Developer Experience):**
- üìâ Menos c√≥digo boilerplate (de ~15 l√≠neas a ~5 l√≠neas por hook)
- üêõ Debugging m√°s f√°cil con DevTools
- üîÑ Sincronizaci√≥n de estado sin l√≥gica manual

**Performance:**
- üöÄ Menos requests al servidor (deduplicaci√≥n)
- üì¶ Cache inteligente (stale-while-revalidate)
- ‚è±Ô∏è Prefetching para navegaci√≥n anticipada

#### Referencias

- **Docs Oficiales:** https://tanstack.com/query/latest
- **Migration Guide:** https://tanstack.com/query/latest/docs/react/guides/migrating-to-v5
- **Best Practices:** https://tkdodo.eu/blog/practical-react-query

#### Riesgos y Mitigaciones

**Riesgo 1:** Curva de aprendizaje del equipo
- **Mitigaci√≥n:** Workshop interno + documentaci√≥n interna con ejemplos

**Riesgo 2:** Breaking changes en hooks existentes
- **Mitigaci√≥n:** Migraci√≥n gradual, mantener hooks legacy temporalmente con deprecation warnings

**Riesgo 3:** Gesti√≥n de cache compleja
- **Mitigaci√≥n:** Definir convenciones claras de `queryKeys` desde el inicio

#### Notas T√©cnicas

- **Compatibilidad:** React Query v5 requiere React 18+ (ya lo usamos)
- **Bundle Size:** ~15KB gzipped (aceptable para los beneficios)
- **SSR compatible:** Para futuro Server-Side Rendering si se requiere

---

## RFC-004: DATASET MANAGEMENT UI

### ‚úÖ Dataset Dashboard Template System (Lista, Detalle, Edit & Dashboard)

**Estado:** ‚úÖ Dise√±o Completado (ver RFC-004-DASHBOARD-TEMPLATE)  
**Prioridad:** Alta  
**Esfuerzo Estimado:** 4-5 d√≠as (post React Query migration)  
**Versi√≥n Target:** v0.4.0  
**RFC:** `docs/design/RFC-004-DASHBOARD-TEMPLATE.md`  
**Dependencias:** RFC-React-Query-Migration (DEBE completarse primero)

#### Contexto

Actualmente, el flujo de datasets termina en el paso 3 (configuraci√≥n de mapping). No existe una UI completa para visualizar, editar y explorar datasets creados.

**RFC-004 implementa:**

1. **DatasetsList Update:** Conectar con API real + botones Edit/Dashboard con feature flag
2. **DatasetDetail Page:** Edici√≥n de metadatos (labels, colors, KPI labels, AI config)
3. **DatasetDashboard:** Sistema de templates para visualizaci√≥n comparativa
4. **Dashboard Templates:** Templates predefinidos (Executive, Trends, Detailed)
5. **Dynamic Filters:** Filtros por dimensiones categ√≥ricas que actualizan toda la vista

#### Arquitectura de Soluci√≥n

**Routing:**
```
/datasets              ‚Üí DatasetsList (lista con API real)
/datasets/new          ‚Üí DataUploadWizard (existente)
/datasets/:id          ‚Üí DatasetDetail (edici√≥n con feature flag)
/datasets/:id/dashboard ‚Üí DatasetDashboard (templates + filtros)
```

**Feature Flag:**
```typescript
FEATURES.DATASET_EDIT_ENABLED = import.meta.env.VITE_FEATURE_DATASET_EDIT_ENABLED === "true"
```

**Campos Editables:**
- `meta.name`, `meta.description`
- `sourceConfig.groupA/B.label`, `sourceConfig.groupA/B.color`
- `schemaMapping.kpiFields[].label`, `schemaMapping.kpiFields[].format`
- `aiConfig.enabled`, `aiConfig.userContext`

**Sistema de Templates:**
```typescript
type DashboardTemplateId = 'sideby_executive' | 'sideby_trends' | 'sideby_detailed';

// sideby_executive: 4 KPIs + gr√°fico principal + tabla
// sideby_trends: Multiple charts con evoluci√≥n temporal
// sideby_detailed: Tabla completa de datos raw
```

#### Implementaci√≥n con React Query

**Hooks principales:**

```typescript
// Queries (READ)
useDatasets()           // Lista con cache autom√°tico
useDataset(id)          // Detalle individual

// Mutations (WRITE) con optimistic updates
useUpdateDataset()      // PATCH con invalidaci√≥n autom√°tica
useDeleteDataset()      // DELETE con optimistic removal

// Dashboard Logic
useDatasetDashboard(id) // Filtros + KPI calculations + Template management
```

**Invalidaci√≥n de Cache:**
```typescript
// Despu√©s de updateDataset, React Query invalida autom√°ticamente:
queryClient.invalidateQueries({ queryKey: ['dataset', id] });  // ‚úÖ Detalle se actualiza
queryClient.invalidateQueries({ queryKey: ['datasets'] });     // ‚úÖ Lista se actualiza
// ‚úÖ Dashboard tambi√©n se actualiza (usa misma queryKey)
```

#### Dashboard Features

1. **KPI Comparison:**
   - Suma autom√°tica de m√©tricas por grupo (groupA vs groupB)
   - C√°lculo de % de cambio
   - Formato seg√∫n KPIField.format (number/currency/percentage)

2. **Dynamic Filters:**
   - Dropdown por cada categoricalField
   - Filtrado aplicado a KPIs, gr√°ficos y tabla
   - Active filters con chips removibles
   - "Limpiar filtros" button

3. **Template Switcher:**
   - Select dropdown para cambiar entre templates
   - Re-renderizado de componentes seg√∫n template activo
   - State persiste en URL (futuro)

4. **Visualizations:**
   - KPIGrid (4 cards m√°ximo para Executive)
   - ComparisonChart (Line/Area/Bar seg√∫n template)
   - ComparisonTable (datos tabulares)
   - AIInsights (an√°lisis con IA si habilitado)

#### Tareas de Implementaci√≥n

**Fase 1: React Query Foundation (2 d√≠as)**
- [x] Dise√±o completado en RFC-React-Query-Migration
- [ ] Implementar migration checklist
- [ ] Tests actualizados con QueryClientProvider wrapper

**Fase 2: DatasetsList Update (0.5 d√≠as)**
- [ ] Conectar `useDatasets` con API real
- [ ] Actualizar `DatasetCard` con botones Edit/Dashboard
- [ ] Feature flag `VITE_FEATURE_DATASET_EDIT_ENABLED`
- [ ] Tests de navegaci√≥n

**Fase 3: DatasetDetail (1.5 d√≠as)**
- [ ] Hook `useUpdateDataset` con optimistic updates
- [ ] P√°gina con React Hook Form + Zod validation
- [ ] Secciones: General, Grupos, KPIs, IA
- [ ] Color pickers para grupos
- [ ] Tests de formulario y mutations

**Fase 4: Dashboard Template System (2 d√≠as)**
- [ ] Types: `DashboardTemplateId`, `TemplateConfig`
- [ ] Hook `useDatasetDashboard` (filtros + KPIs + template)
- [ ] Component `TemplateRenderer` (renderizado din√°mico)
- [ ] Component `DashboardFilters` (dropdowns + chips)
- [ ] Components: `KPIGrid`, `ComparisonChart`, `ComparisonTable`
- [ ] Template switcher UI
- [ ] Tests de c√°lculos y filtros

**Fase 5: Integration & Polish (1 d√≠a)**
- [ ] Routing completo
- [ ] Loading states (Skeletons)
- [ ] Error boundaries
- [ ] Empty states
- [ ] Tests E2E del flujo completo
- [ ] Performance testing

#### Limitaciones Conocidas & Tareas Pendientes Backend

### üîß Backend: Soportar edici√≥n de `sourceConfig` en endpoint PATCH

**Estado:** Pendiente (Bloqueador para edici√≥n completa de grupos)  
**Prioridad:** Media  
**Esfuerzo Estimado:** 1 d√≠a  
**Versi√≥n Target:** v0.4.1  
**Bloqueado por:** Phase 6 de RFC-004

#### Contexto

Durante la implementaci√≥n de **Phase 6: DatasetDetail Edit Page** (RFC-004), se identific√≥ que el backend endpoint `PATCH /api/v1/datasets/:id` **NO soporta actualizar `sourceConfig`**.

**Schema actual (UpdateMappingSchema):**
```typescript
{
  meta: { name, description },           // ‚úÖ Soportado
  schemaMapping: { ... },                // ‚úÖ Soportado
  dashboardLayout: { ... },              // ‚úÖ Soportado
  aiConfig: { enabled, userContext }     // ‚úÖ Soportado
  // ‚ùå sourceConfig NO est√° en el schema
}
```

**Problema:**
- Frontend permite mostrar y eventualmente editar `sourceConfig.groupA/B.label` y `sourceConfig.groupA/B.color`
- Backend rechaza el payload si se env√≠a `sourceConfig` (Zod validation error)
- Los labels y colores de grupos son **inmutables** despu√©s del upload inicial

#### Soluci√≥n Propuesta

**Opci√≥n A: Extender UpdateMappingSchema (Recomendada)**

Actualizar el schema Zod para aceptar cambios en labels y colores:

```typescript
// apps/api/src/modules/datasets/presentation/validators/datasets.schemas.ts

export const UpdateMappingSchema = z.object({
  meta: z.object({ ... }),
  schemaMapping: z.object({ ... }),
  dashboardLayout: z.object({ ... }),
  aiConfig: z.object({ ... }).optional(),
  
  // ‚ú® NUEVO: Permitir editar configuraci√≥n de grupos
  sourceConfig: z.object({
    groupA: z.object({
      label: z.string().min(1).max(50),
      color: z.string().regex(/^#[0-9A-Fa-f]{6}$/),
      // originalFileName y rowCount NO editables
    }).partial(),
    groupB: z.object({
      label: z.string().min(1).max(50),
      color: z.string().regex(/^#[0-9A-Fa-f]{6}$/),
    }).partial(),
  }).optional(),
});
```

**Opci√≥n B: Endpoint separado (Menos prioritario)**

Crear `PATCH /api/v1/datasets/:id/groups` espec√≠fico para editar grupos:
- Ventaja: Separaci√≥n de responsabilidades
- Desventaja: M√°s complejidad (2 mutations en frontend)

#### Tareas de Implementaci√≥n

- [ ] **Backend:**
  - [ ] Actualizar `UpdateMappingSchema` con `sourceConfig` opcional
  - [ ] Validar que solo se editen `label` y `color` (no `originalFileName`, `rowCount`)
  - [ ] Actualizar `UpdateMappingUseCase` para aplicar cambios a `sourceConfig`
  - [ ] Tests unitarios para validaci√≥n y actualizaci√≥n
  - [ ] Tests de integraci√≥n para endpoint PATCH

- [ ] **Frontend (despu√©s de backend):**
  - [ ] Habilitar edici√≥n de labels y colores en `GroupConfigFields` component
  - [ ] Actualizar `useUpdateDataset` hook para enviar `sourceConfig` en payload
  - [ ] Tests de formulario con edici√≥n de grupos

#### Workaround Temporal (Phase 6)

Mientras el backend no soporte edici√≥n de `sourceConfig`:

1. **Mostrar campos como disabled** (read-only) en `GroupConfigFields.tsx`
2. **Agregar tooltip explicativo:** "Los labels y colores de grupos se configuran en el upload inicial. Pr√≥ximamente podr√°s editarlos aqu√≠."
3. **NO enviar `sourceConfig` en el payload** de `updateDataset` mutation
4. **Color picker visible pero disabled** (para preparar UI)

**Nota en c√≥digo:**
```typescript
// GroupConfigFields.tsx
// TODO: Habilitar edici√≥n cuando backend soporte PATCH de sourceConfig
// Ver: docs/ROADMAP.md ‚Üí RFC-004 ‚Üí Backend: Soportar edici√≥n de sourceConfig
<Input disabled value={groupALabel} ... />
```

#### Mejora Adicional: Wizard Upload con Nombres de Archivo

**Relacionado:** En vez de usar "Grupo A" y "Grupo B" por defecto en el wizard de upload, usar los nombres de archivo originales.

**Cambio en `DataUploadWizard`:**
```typescript
// Antes:
const defaultGroupALabel = "Grupo A"; // ‚ùå Gen√©rico

// Despu√©s:
const defaultGroupALabel = fileA.name.replace(/\.csv$/i, ''); // ‚úÖ "performance_2023"
```

Esto hace que los datasets tengan labels m√°s descriptivos desde el inicio y reduce la necesidad de editarlos posteriormente.

#### Beneficios Esperados

**UX:**
- ‚úÖ Ciclo CRUD completo de datasets
- ‚ö° Feedback inmediato con optimistic updates (sin esperar al servidor)
- üé® Templates flexibles para diferentes necesidades (Executive, Trends, Detailed)
- üîç Filtros din√°micos que sincronizan KPIs, gr√°ficos y tabla
- üìä Comparaci√≥n visual groupA vs groupB con colores personalizables

**DX:**
- üì¶ React Query elimina ~300 l√≠neas de boilerplate
- üß™ Tests comprehensivos con alta cobertura
- üèóÔ∏è Arquitectura escalable para nuevos templates
- üìö Documentaci√≥n TDD completa en RFCs

**Performance:**
- üöÄ Cache inteligente reduce requests al backend
- üìä C√°lculos de KPIs memoizados (solo recalcula si cambian filtros)
- ‚è±Ô∏è Prefetching potencial al hover sobre dataset cards

#### Referencias

- **RFC Completo:** `docs/design/RFC-004-DASHBOARD-TEMPLATE.md`
- **RFC Dependency:** `docs/design/RFC-React-Query-Migration.md`
- **Componentes de Referencia:** `SideBy-Design/src/pages/Dashboard.tsx`
- **Backend Entity:** `apps/api/src/modules/datasets/domain/Dataset.entity.ts`

#### Riesgos y Mitigaciones

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|--------------|---------|------------|
| Performance con datasets grandes (>10K rows) | Media | Alta | Virtualizaci√≥n en tabla, memoizaci√≥n, paginaci√≥n en gr√°ficos |
| Complejidad de filtros anidados | Baja | Media | Limitar a filtros simples en MVP, mejorar en v0.5 |
| Feature flag no cubre todos los casos | Media | Baja | Tests de ambos estados (enabled/disabled) |

#### Pr√≥ximos Pasos (v0.5.0)

- Export dashboard a PDF
- Compartir datasets entre usuarios
- Custom templates (drag & drop editor)
- Anotaciones en gr√°ficos
- Alertas basadas en umbrales

---

## INFRASTRUCTURE & OBSERVABILITY

### Mejoras Planificadas

### üìä Structured Logging System with Sentry Integration

**Estado:** Propuesta  
**Prioridad:** Media  
**Esfuerzo Estimado:** S (1-3 d√≠as)  
**Versi√≥n Target:** v0.5.0

#### Contexto

Durante el desarrollo y debugging de features (ej: RFC-004 highlighted KPIs fix), se identific√≥ la necesidad de logs estructurados que:
- Se muestren **solo en desarrollo**, no contaminen la consola en producci√≥n
- Tengan **niveles claros** (debug, info, warn, error)
- Sean **extensibles** para integrar con servicios de observability (Sentry, LogRocket)
- Mantengan **performance √≥ptimo** en producci√≥n (sin overhead de console.log)

**Problema actual:**
```typescript
// ‚ùå Logs ad-hoc durante debugging
console.log('[Component] Some debug info:', data);
console.log('[Hook] State update:', state);

// Problemas:
// 1. Se ejecutan en producci√≥n (contamina consola del usuario)
// 2. Sin estructura ni niveles
// 3. Dif√≠cil de deshabilitar globalmente
// 4. No se integran con error tracking
```

#### Soluci√≥n Propuesta

Implementar un **Logger Service** con detecci√≥n autom√°tica de entorno:

**1. Logger Utility (`src/shared/utils/logger.ts`):**
```typescript
const isDev = import.meta.env.MODE === 'development';
const isTest = import.meta.env.MODE === 'test';

export const logger = {
  /**
   * Debug logs - Solo en desarrollo
   * Uso: Debugging de flujos, state changes, data transformations
   */
  debug: (...args: unknown[]) => {
    if (isDev) console.log('[DEBUG]', ...args);
  },

  /**
   * Info logs - Solo en desarrollo
   * Uso: Operaciones importantes, API calls success, milestones
   */
  info: (...args: unknown[]) => {
    if (isDev) console.info('[INFO]', ...args);
  },

  /**
   * Warning logs - Siempre mostrar
   * Uso: Deprecated APIs, fallbacks, validation warnings
   */
  warn: (...args: unknown[]) => {
    console.warn('[WARN]', ...args);
    // TODO: Enviar a Sentry como warning
  },

  /**
   * Error logs - Siempre mostrar + Enviar a Sentry
   * Uso: Exceptions, API errors, critical failures
   */
  error: (error: Error | unknown, ...args: unknown[]) => {
    console.error('[ERROR]', error, ...args);
    // TODO: Sentry.captureException(error, { extra: { ...args } });
  },

  /**
   * Performance timing
   */
  time: (label: string) => {
    if (isDev) console.time(`[PERF] ${label}`);
  },

  timeEnd: (label: string) => {
    if (isDev) console.timeEnd(`[PERF] ${label}`);
  },
};
```

**2. Uso en C√≥digo:**
```typescript
// Componentes
import { logger } from '@/shared/utils/logger.js';

function useWizardState() {
  const setMapping = (mapping: Partial<ColumnMapping>) => {
    logger.debug('[useWizardState] setMapping called:', {
      kpiFieldsCount: mapping.kpiFields?.length,
      hasHighlighted: mapping.kpiFields?.some(k => k.highlighted),
    });
    
    setState(mapping);
  };
}

// Error Boundaries
function ErrorBoundary() {
  componentDidCatch(error: Error, errorInfo: ErrorInfo) {
    logger.error(error, { componentStack: errorInfo.componentStack });
  }
}

// API Calls
async function fetchDataset(id: string) {
  logger.debug('[API] Fetching dataset:', id);
  logger.time('fetchDataset');
  
  try {
    const response = await axios.get(`/datasets/${id}`);
    logger.debug('[API] Dataset fetched successfully');
    return response.data;
  } catch (error) {
    logger.error(error, { datasetId: id, endpoint: '/datasets/:id' });
    throw error;
  } finally {
    logger.timeEnd('fetchDataset');
  }
}
```

**3. Sentry Integration (Fase 2):**
```typescript
import * as Sentry from '@sentry/react';

export const logger = {
  error: (error: Error | unknown, context?: Record<string, unknown>) => {
    console.error('[ERROR]', error, context);
    
    if (import.meta.env.PROD && Sentry.isInitialized()) {
      Sentry.captureException(error, {
        level: 'error',
        extra: context,
        tags: {
          feature: context?.feature || 'unknown',
        },
      });
    }
  },

  warn: (message: string, context?: Record<string, unknown>) => {
    console.warn('[WARN]', message, context);
    
    if (import.meta.env.PROD && Sentry.isInitialized()) {
      Sentry.captureMessage(message, {
        level: 'warning',
        extra: context,
      });
    }
  },
};
```

#### Tareas de Implementaci√≥n

**Sprint 1 - Basic Logger (1-2 d√≠as):**
- [ ] Crear `src/shared/utils/logger.ts` con m√©todos debug/info/warn/error
- [ ] Agregar detecci√≥n de entorno (dev/test/prod)
- [ ] Implementar performance timing helpers
- [ ] Tests unitarios para logger utility

**Sprint 2 - Code Migration (1 d√≠a):**
- [ ] Migrar console.log existentes a logger.debug() en:
  - [ ] Wizard components (useWizardState, ColumnMappingStep, DataUploadWizard)
  - [ ] API hooks (useDataset, useUpdateDataset)
  - [ ] Error boundaries
- [ ] Agregar logs estrat√©gicos en flujos cr√≠ticos:
  - [ ] Dataset creation flow
  - [ ] Authentication flow
  - [ ] Data validation/parsing

**Sprint 3 - Sentry Integration (1 d√≠a):**
- [ ] Setup Sentry SDK (`@sentry/react` + `@sentry/vite-plugin`)
- [ ] Configurar Sentry.init() en `main.tsx`
- [ ] Integrar logger.error() con Sentry.captureException()
- [ ] Configurar source maps para stack traces
- [ ] Environment variables: `VITE_SENTRY_DSN`, `VITE_SENTRY_ENVIRONMENT`

**Sprint 4 - Documentaci√≥n (0.5 d√≠as):**
- [ ] Gu√≠a de uso del logger en `docs/DEV_GUIDE.md`
- [ ] Ejemplos de logging patterns
- [ ] Configuraci√≥n de Sentry en README

#### Beneficios

1. **Developer Experience:**
   - Logs estructurados facilitan debugging
   - No m√°s console.log olvidados en producci√≥n
   - Performance timing out-of-the-box

2. **Production Monitoring:**
   - Errores capturados autom√°ticamente en Sentry
   - Context enriquecido (user, feature, breadcrumbs)
   - Alertas en tiempo real v√≠a Sentry

3. **Performance:**
   - logger.debug() es no-op en producci√≥n (0 overhead)
   - Conditional logging basado en entorno
   - Tree-shaking elimina c√≥digo no usado

#### Referencias

- **Sentry Docs:** https://docs.sentry.io/platforms/javascript/guides/react/
- **Logger Patterns:** https://12factor.net/logs
- **Related:** Error Boundary implementation (`src/shared/components/ErrorBoundary.tsx`)

#### Notas T√©cnicas

- **Tree-shaking:** Vite elimina autom√°ticamente `logger.debug()` calls en prod builds si est√°n detr√°s de `if (isDev)`
- **Source Maps:** Configurar `sourcemaps: true` en `vite.config.ts` solo para prod builds
- **Sentry Rate Limits:** Configurar sample rates para no exceder free tier (10k events/month)

---

## RFC-005: Dashboard UX Improvements

### Mejoras Implementadas (v0.5.0)

‚úÖ **Multi-select Filters:** Permite seleccionar m√∫ltiples valores en cada dimensi√≥n  
‚úÖ **Active Filter Chips:** Chips removibles con bot√≥n "Limpiar todos"  
‚úÖ **Enhanced Template Selector:** Selector mejorado con √≠conos y descripciones  

Ver detalles en: [`docs/design/RFC-005-DASHBOARD-UX-IMPROVEMENTS.md`](design/RFC-005-DASHBOARD-UX-IMPROVEMENTS.md)

### Mejoras Pendientes (v0.6.0)

**üîÑ Auto-save Template Preference**

**Estado:** Pendiente  
**Prioridad:** Media  
**Esfuerzo Estimado:** 1-2 d√≠as (0.5d Backend + 1d Frontend + 0.5d Testing)  
**Versi√≥n Target:** v0.6.0  
**Bloqueador:** Requiere endpoint backend que acepte `dashboardLayout.templateId`

#### Contexto

Durante la implementaci√≥n de RFC-005, se identific√≥ que el selector de templates mejorado necesita persistir la preferencia del usuario. Actualmente el template seleccionado se pierde al recargar la p√°gina.

**User Story:**
> Como usuario, cuando cambio de "Resumen Ejecutivo" a "An√°lisis de Tendencias", quiero que mi preferencia se guarde autom√°ticamente para que la pr√≥xima vez que abra el dashboard se muestre la misma vista.

#### Soluci√≥n Propuesta

**Backend (0.5 d√≠as):**
- Extender endpoint `PATCH /api/v1/datasets/:id` para aceptar:
  ```json
  { "dashboardLayout": { "templateId": "sideby_trends" } }
  ```
- Validar `templateId` como enum v√°lido
- Manejo de errores para template inv√°lido

**Frontend (1 d√≠a):**
- Implementar auto-save con debounce (2 segundos despu√©s del cambio)
- Visual feedback: "Guardando..." ‚Üí "‚úì Guardado" ‚Üí "No guardado"
- Integraci√≥n con `useUpdateDataset` mutation hook
- Error handling silencioso con logging (no toasts intrusivos)
- Tests con fake timers para validar debounce

**Testing (0.5 d√≠as):**
- Unit tests: l√≥gica de debounce y estado de guardado
- Integration tests: mutation + cache invalidation
- E2E test: Cambiar template ‚Üí Recargar p√°gina ‚Üí Validar persistencia

#### Referencias
- Component: `components/dashboard/TemplateSelector.tsx`
- Hook: `hooks/useUpdateDataset.ts`

---

## RFC-006: Dashboard Visualization Enhancements

### Mejoras Planificadas (v0.6.0)

üìÖ **Date Umbrella System:** Sistema para alinear fechas de diferentes per√≠odos  
üìä **Executive View:** KPI cards con sparklines + gr√°fico configurable  
üìà **Trends View:** Grid 2√ó2 de mini-charts con trend indicators  
üìã **Detailed View:** Tabla totales + tabla granular con deltas y export CSV  

üß≠ **KPIs con m√©trica inversa:** Soporte para m√©tricas donde ‚Äúmenos es mejor‚Äù (ej: costos, churn, tiempos).  
Requiere persistir un flag por KPI y ajustar c√°lculo de tendencia/colores.

Ver detalles en: [`docs/design/RFC-006-DASHBOARD-VISUALIZATION-ENHANCEMENTS.md`](design/RFC-006-DASHBOARD-VISUALIZATION-ENHANCEMENTS.md)

---

## RFC-007: Dashboard PDF Export

### Mejoras Planificadas (v0.7.0)

üìÑ **PDF Export System:** Exportaci√≥n interactiva de dashboards a PDF  
üîó **Interactive Links:** PDFs con links funcionales al dashboard online  
‚öôÔ∏è **Section Selector:** Usuario elige qu√© secciones exportar  
üé® **A4 Optimized:** Layout optimizado para impresi√≥n profesional  

Ver detalles en: [`docs/design/RFC-007-DASHBOARD-PDF-EXPORT.md`](design/RFC-007-DASHBOARD-PDF-EXPORT.md)

---

## RFC-008: AI Insights Service

### Mejoras Planificadas

**Phase 1 (v0.5.0):** Rule Engine con insights b√°sicos  
**Phase 2 (v0.6.0):** Integraci√≥n con LLMs (GPT-4/Claude)  
**Phase 3 (v0.7.0+):** Fine-tuning, feedback loop, predicciones  

ü§ñ **AI-Powered Insights:** An√°lisis autom√°tico de datos con contexto  
üìä **5 Tipos de Insights:** Summary, Warning, Suggestion, Trend, Anomaly  
üí° **Confidence Scoring:** Nivel de confianza por cada insight  
üîÑ **Fallback Strategy:** Rule Engine como backup si falla LLM  

Ver detalles en: [`docs/design/RFC-008-AI-INSIGHTS-SERVICE.md`](design/RFC-008-AI-INSIGHTS-SERVICE.md)

---

## FEATURES FUTURAS (v1.0+)

### üîó Compartir Dashboard (Share Dashboard Links)

**Estado:** Propuesta  
**Prioridad:** Media  
**Esfuerzo Estimado:** 2-3 d√≠as  
**Versi√≥n Target:** v1.0.0

#### Contexto

Los usuarios necesitan compartir dashboards con stakeholders externos sin requerir que creen cuentas en SideBy. Actualmente no existe un mecanismo de compartir p√∫blicamente.

**User Story:**
> Como usuario, quiero generar un link p√∫blico de mi dashboard para compartirlo con mi equipo o clientes externos, de forma que puedan ver los datos sin necesidad de login.

#### Soluci√≥n Propuesta

**1. Generar Link P√∫blico con Token JWT**

- Endpoint: `POST /api/v1/datasets/:id/share`
- Generar un token JWT con payload:
  ```json
  {
    "datasetId": "65f...",
    "expiresAt": "2026-12-31T23:59:59Z",
    "permissions": ["read"],
    "filters": { "categorical": { "Region": ["Norte"] } }
  }
  ```
- Guardar share link en DB con metadata:
  ```typescript
  interface ShareLink {
    _id: ObjectId;
    datasetId: ObjectId;
    token: string;
    createdBy: ObjectId;
    createdAt: Date;
    expiresAt: Date;
    accessCount: number;
    lastAccessedAt?: Date;
    filters?: DashboardFilters;
    isActive: boolean;
  }
  ```

**2. Public Dashboard Route**

- Frontend: `/public/datasets/:token`
- No requiere autenticaci√≥n
- Muestra dashboard en modo "read-only" (sin edici√≥n)
- Header indica "Vista P√∫blica" con badge
- Footer: "Creado con SideBy" + logo

**3. Share Modal UI**

```typescript
<ShareDashboardModal>
  <Input value={shareUrl} readOnly />
  <CopyButton />
  
  <DatePicker label="Fecha de expiraci√≥n" />
  
  <Checkbox label="Aplicar filtros actuales" />
  
  <Button onClick={generateShareLink}>
    Generar Link
  </Button>
</ShareDashboardModal>
```

**4. Opciones de Expiraci√≥n**

- 1 d√≠a
- 7 d√≠as
- 30 d√≠as
- Sin expiraci√≥n (solo para usuarios premium)

#### Seguridad

- **Rate Limiting:** M√°ximo 10 share links por dataset
- **Token Expiration:** Auto-revoke al expirar
- **Analytics:** Track access count y last accessed
- **Revocation:** Bot√≥n para desactivar link en cualquier momento
- **Watermark:** Opcional "Compartido por [User Name]" en footer

#### Implementaci√≥n

**Backend:**
- `src/modules/share/domain/ShareLink.ts` (Entity)
- `src/modules/share/application/GenerateShareLinkUseCase.ts`
- `src/modules/share/infrastructure/ShareLinkRepository.ts`
- `src/modules/share/presentation/ShareController.ts`

**Frontend:**
- `src/features/dataset/components/dashboard/ShareDashboardModal.tsx`
- `src/pages/PublicDashboard.tsx` (nueva p√°gina sin auth)
- `src/features/dataset/hooks/useShareDashboard.ts`

#### Limitaciones MVP

- No soporta edici√≥n de filtros en vista p√∫blica (filtros fijos del momento de share)
- No incluye AI Insights en vista p√∫blica (solo KPIs y gr√°ficos)
- No permite exportar PDF desde vista p√∫blica

#### Extensiones Futuras (v1.1+)

- **Password Protection:** Proteger link con contrase√±a
- **Email Sharing:** Enviar link directamente por email desde la app
- **Embed Code:** Generar iframe para embeber dashboard en sitios externos
- **Analytics Dashboard:** Ver qui√©n accedi√≥, cu√°ndo, desde d√≥nde (IP, country)

---

### üîî Configurar Alertas (Alerts & Notifications)

**Estado:** Propuesta  
**Prioridad:** Media  
**Esfuerzo Estimado:** 5-7 d√≠as  
**Versi√≥n Target:** v1.0.0

#### Contexto

Los usuarios necesitan ser notificados autom√°ticamente cuando ciertos KPIs alcanzan umbrales cr√≠ticos (ej: Revenue baja >20%, Churn sube >15%). Actualmente deben revisar el dashboard manualmente.

**User Story:**
> Como usuario, quiero configurar alertas para que me notifiquen por email cuando Revenue caiga m√°s de 20% respecto al per√≠odo anterior, para tomar acciones correctivas de inmediato.

#### Soluci√≥n Propuesta

**1. Alert Configuration Entity**

```typescript
interface DatasetAlert {
  _id: ObjectId;
  datasetId: ObjectId;
  userId: ObjectId;
  
  name: string;  // "Alerta de Revenue Bajo"
  description?: string;
  
  conditions: {
    kpi: string;  // "revenue"
    operator: 'greater_than' | 'less_than' | 'equals' | 'change_percent_above' | 'change_percent_below';
    threshold: number;
    compareWith?: 'previous_period' | 'absolute_value';
  }[];
  
  notificationChannels: ('email' | 'in-app' | 'webhook')[];
  
  emailConfig?: {
    recipients: string[];
    subject: string;
    template: string;
  };
  
  webhookConfig?: {
    url: string;
    method: 'POST' | 'GET';
    headers?: Record<string, string>;
  };
  
  schedule: {
    frequency: 'real-time' | 'daily' | 'weekly' | 'monthly';
    time?: string;  // HH:mm format (para daily)
    dayOfWeek?: number;  // 0-6 (para weekly)
    dayOfMonth?: number;  // 1-31 (para monthly)
  };
  
  lastTriggeredAt?: Date;
  triggerCount: number;
  isActive: boolean;
  createdAt: Date;
  updatedAt: Date;
}
```

**2. Alert Evaluation Cron Job**

- Ejecutar seg√∫n schedule configurado
- Evaluar condiciones contra datos actuales
- Si se cumple condici√≥n ‚Üí trigger notifications
- Implementar "cooldown period" (no retriggear si ya se dispar√≥ en √∫ltimas X horas)

```typescript
// alert-evaluation.job.ts
export async function evaluateAlerts(): Promise<void> {
  const activeAlerts = await alertRepository.findActive();
  
  for (const alert of activeAlerts) {
    const dataset = await datasetRepository.findById(alert.datasetId);
    const currentKPI = calculateKPI(dataset.data, alert.conditions[0].kpi);
    
    if (shouldTriggerAlert(currentKPI, alert.conditions)) {
      await notificationService.send(alert);
      await alertRepository.updateLastTriggered(alert._id);
    }
  }
}
```

**3. Frontend: Alert Configuration UI**

```typescript
<ConfigureAlertsModal>
  <Input label="Nombre de la alerta" />
  
  <Select label="KPI a monitorear">
    <option>Revenue</option>
    <option>Traffic</option>
    <option>ROI</option>
    <option>Churn Rate</option>
  </Select>
  
  <Select label="Condici√≥n">
    <option>Disminuye m√°s de</option>
    <option>Aumenta m√°s de</option>
    <option>Es mayor que</option>
    <option>Es menor que</option>
  </Select>
  
  <Input type="number" label="Umbral (%)" />
  
  <Checkbox label="Notificar por Email" />
  <Checkbox label="Notificar en App" />
  <Checkbox label="Webhook (avanzado)" />
  
  <Select label="Frecuencia de evaluaci√≥n">
    <option>Diaria (9:00 AM)</option>
    <option>Semanal (Lunes 9:00 AM)</option>
    <option>Mensual (D√≠a 1, 9:00 AM)</option>
  </Select>
  
  <Button>Crear Alerta</Button>
</ConfigureAlertsModal>
```

**4. In-App Notifications**

- Nueva secci√≥n en header: "üîî Notificaciones" con badge de count
- Dropdown con lista de notificaciones recientes
- Formato:
  ```
  üö® Revenue baj√≥ 23% en Dataset "Q1 2024"
  Hace 2 horas ‚Ä¢ Ver Dashboard ‚Üí
  ```

**5. Email Notifications**

- Template HTML profesional
- Subject: `[SideBy Alert] Revenue baj√≥ 23% en Dataset "Q1 2024"`
- Body:
  - Nombre de la alerta
  - Condici√≥n que se cumpli√≥
  - Valor actual vs esperado
  - Link directo al dashboard
  - Bot√≥n "Desactivar esta alerta"

#### Implementaci√≥n

**Backend:**
- `src/modules/alerts/domain/DatasetAlert.ts`
- `src/modules/alerts/application/CreateAlertUseCase.ts`
- `src/modules/alerts/application/EvaluateAlertsUseCase.ts`
- `src/modules/alerts/infrastructure/AlertRepository.ts`
- `src/modules/alerts/jobs/alert-evaluation.job.ts`
- `src/modules/notifications/infrastructure/EmailService.ts` (usar Nodemailer/SendGrid)

**Frontend:**
- `src/features/dataset/components/dashboard/ConfigureAlertsModal.tsx`
- `src/features/alerts/components/AlertsList.tsx`
- `src/features/alerts/components/NotificationDropdown.tsx`
- `src/features/alerts/hooks/useAlerts.ts`

#### Seguridad & Performance

- **Rate Limiting:** M√°ximo 5 alertas activas por dataset (plan free), 20 (premium)
- **Cooldown Period:** No retriggear misma alerta si ya se dispar√≥ en √∫ltimas 6 horas
- **Email Limits:** M√°ximo 10 emails por d√≠a por usuario (evitar spam)
- **Webhook Timeout:** 5 segundos m√°ximo (evitar bloqueos)

#### Limitaciones MVP

- Solo condiciones simples (un solo KPI por alerta)
- No soporta condiciones complejas (AND/OR m√∫ltiples KPIs)
- No incluye notificaciones SMS/Slack (solo email + in-app + webhook)
- No hay "snooze" de alertas

#### Extensiones Futuras (v1.1+)

- **Complex Conditions:** Multiple KPIs con AND/OR logic
- **AI-Powered Alerts:** Detectar anomal√≠as autom√°ticamente sin configuraci√≥n manual
- **Slack Integration:** Enviar alertas a canales de Slack
- **Alert History:** Dashboard de historial de alertas disparadas
- **Alert Templates:** Plantillas pre-configuradas ("Revenue Drop", "Churn Spike")

---



## Convenciones

### Estados
- **Propuesta:** Mejora identificada, pendiente de dise√±o detallado
- **En Dise√±o:** RFC en creaci√≥n, buscando feedback
- **Aprobada:** Dise√±o validado, lista para implementaci√≥n
- **En Desarrollo:** Trabajo en progreso
- **Completada:** Mergeada a `main`

### Prioridad
- **Alta:** Blocking para siguiente release
- **Media:** Important but not urgent
- **Baja:** Nice to have

### Esfuerzo Estimado
- **XS:** < 1 d√≠a
- **S:** 1-3 d√≠as
- **M:** 3-5 d√≠as
- **L:** 1-2 semanas
- **XL:** > 2 semanas

---

**√öltima Actualizaci√≥n:** 2026-02-13  
**Mantenido por:** Engineering Team
